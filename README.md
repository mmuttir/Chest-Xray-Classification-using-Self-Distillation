# XceptionNet with CBAM: Attention-based Image Classification

This repository contains an implementation of the XceptionNet architecture enhanced with Convolutional Block Attention Module (CBAM) for improved image classification. The main goal of this project is to leverage the power of XceptionNet and enhance its capabilities by incorporating attention mechanisms through CBAM. This implementation is designed to be easy to use and extend.


## Introduction

[XceptionNet](https://arxiv.org/abs/1610.02357) is a powerful and efficient deep learning architecture for image classification tasks. It employs depthwise separable convolutions to significantly reduce the number of parameters without sacrificing performance. [CBAM](https://arxiv.org/abs/1807.06521) (Convolutional Block Attention Module) is an attention mechanism that enhances the feature representation of CNNs by focusing on important spatial and channel-wise information. By combining XceptionNet with CBAM, we aim to improve the model's performance on various image classification tasks.


## Model Overview

The model is a combination of XceptionNet and CBAM. Here is a brief overview of both components:

### XceptionNet

[XceptionNet](https://arxiv.org/abs/1610.02357) (short for "Extreme Inception") is a deep learning architecture for image classification. It was proposed by Fran√ßois Chollet, the creator of Keras, as an extension of the Inception architecture. XceptionNet uses depthwise separable convolutions, which significantly reduce the number of parameters and computational cost, without compromising performance.

The main idea behind XceptionNet is to replace the standard Inception modules with depthwise separable convolutions, forming the so-called "Xception modules." These modules consist of depthwise convolutions followed by pointwise convolutions, which separate the spatial and channel-wise correlations in the feature maps. This separation allows the model to learn more complex representations with fewer parameters.

### Convolutional Block Attention Module (CBAM)

[CBAM](https://arxiv.org/abs/1807.06521) is an attention mechanism designed to improve the feature representation of CNNs. CBAM consists of two sequential attention modules: channel attention and spatial attention. The channel attention module focuses on the most important channels in the feature maps, while the spatial attention module emphasizes the most important spatial locations.

CBAM can be easily integrated into any CNN architecture by adding it after each convolutional block. In our implementation, we added CBAM after each Xception module to enhance the model's feature representation capabilities.


## Results

The performance of the XceptionNet with CBAM model may vary depending on the dataset, training settings, and hardware used. However, combining XceptionNet with CBAM has been shown to improve the model's performance on various image classification tasks. We encourage you to train the model on your dataset and share your results with the community.




